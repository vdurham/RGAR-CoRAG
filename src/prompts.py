from typing import List, Dict, Optional


def get_generate_subquery_prompt(query: str, 
                                 past_subqueries: List[str], 
                                 past_subanswers: List[str],
                                 extracted_facts: List[str] = None) -> List[Dict]:
    """
    Generate a subquery prompt that integrates CoRAG's iterative approach with RGAR's factual knowledge.
    
    Returns:
        messages: Prompt messages for the LLM
    """
    assert len(past_subqueries) == len(past_subanswers)
    past = ''
    for idx in range(len(past_subqueries)):
        past += f"""Intermediate query {idx+1}: {past_subqueries[idx]} \n Intermediate answer {idx + 1}: {past_subanswers[idx]}\n"""
    past = past.strip()
    
    # Format extracted facts if available
    facts_section = ""
    if extracted_facts and len(extracted_facts) > 0:
        facts_section = "## Extracted Patient Facts\n"
        for fact in extracted_facts:
            facts_section += f"- {fact}\n"
    
    prompt = f"""You are a medical search expert helping to diagnose and answer clinical questions by generating targeted search queries. Given the patient information, previously generated queries, and medical knowledge, generate a new focused follow-up question that will help answer the main clinical query.
{facts_section}
## Previous intermediate queries and answers
{past or 'Nothing yet'}
## Main medical query to answer
{query}
Generate a specific, focused follow-up question that addresses key medical details from the patient record or explores important diagnosis-related concepts mentioned in the knowledge areas. Your question should help a medical search engine find relevant clinical information for diagnosis or treatment. Respond with only the follow-up question, no explanation."""

    messages: List[Dict] = [
        {'role': 'user', 'content': prompt}
    ]
    return messages


def get_generate_intermediate_answer_prompt(subquery: str, documents: List[str], max_tokens: int = 4096) -> List[Dict]:
    prompt_template = """Given the following documents, generate an appropriate answer for the query. DO NOT hallucinate any information, only use the provided documents to generate the answer. Respond "No relevant information found" if the documents do not contain useful information.
## Documents
{context}
## Query
{subquery}
Respond with a concise answer only, do not explain yourself or output anything else."""
    
    # Calculate tokens for the fixed parts (approximate)
    fixed_tokens = len(prompt_template.split()) + len(subquery.split())
    max_doc_tokens = max_tokens - fixed_tokens
    
    # Build context while respecting token limit
    context = ''
    current_tokens = 0
    
    for doc in documents:
        doc_tokens = len(doc.split())
        if current_tokens + doc_tokens > max_doc_tokens:
            # If we can't fit the whole document, stop adding more
            break
        context += f"{doc}\n"
        current_tokens += doc_tokens
    
    # Format the final prompt
    prompt = prompt_template.format(
        context=context.strip(),
        subquery=subquery
    )
    
    messages: List[Dict] = [
        {'role': 'user', 'content': prompt}
    ]
    return messages


def get_generate_final_answer_prompt(
        query, past_subqueries, past_subanswers, context, options) -> List[Dict]:

    assert len(past_subqueries) == len(past_subanswers)
    past = ''
    for idx in range(len(past_subqueries)):
        past += f"""Intermediate query {idx+1}: {past_subqueries[idx]} \n Intermediate answer {idx+1}: {past_subanswers[idx]}\n"""
    past = past.strip()

    prompt = f"""Given the following intermediate queries and answers, generate a final answer for the main query by combining relevant information. Note that intermediate answers are generated by an LLM and may not always be accurate.
## Documents
{context}
## Intermediate queries and answers
{past or 'Nothing yet'}
## Main query
{query}
## Options
{options}
Please generate your output in JSON format as {{"answer_choice": "X"}}. Do not include any other text or explanations."""

    messages: List[Dict] = [
        {'role': 'user', 'content': prompt}
    ]
    return messages
